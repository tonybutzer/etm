{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import fsspec\n",
    "import os\n",
    "import rasterio as rio\n",
    "from math import e\n",
    "from osgeo import gdal, osr, gdal_array, gdalconst\n",
    "import pandas as pd\n",
    "import re\n",
    "import earthpy.spatial as es\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import sys\n",
    "import ogr\n",
    "from osgeo.gdalnumeric import *\n",
    "from osgeo.gdalconst import *\n",
    "from contextlib import contextmanager \n",
    "from rasterio import Affine, MemoryFile\n",
    "from rasterio.enums import Resampling\n",
    "import rioxarray\n",
    "from shapely.geometry import Point, Polygon\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import box\n",
    "from fiona.crs import from_epsg\n",
    "from matplotlib import pyplot as plt\n",
    "from rasterio.plot import plotting_extent\n",
    "import earthpy.plot as ep\n",
    "import math\n",
    "\n",
    "def lapply_brick(original_list,var_name,originalfolder,tiffolder,data_source,to_clip,bounds, pad_factor):\n",
    "    \n",
    "    # Returns list of open DatasetReader geoTIFFs from rasterio\n",
    "\n",
    "    final_list=[]\n",
    "    j=0\n",
    "    for j in range(0, len(original_list)):\n",
    "        \n",
    "        if((data_source == 'METDATA') or (data_source == 'gridMET') or (data_source == 'Historical1915-LIVNEH')):\n",
    "            \n",
    "            fs = fsspec.filesystem('s3')\n",
    "            fobj = fs.open(original_list[j])\n",
    "            xds = xr.open_dataset(fobj)\n",
    "            \n",
    "            if((data_source == 'METDATA') or (data_source == 'gridMET')):\n",
    "                orig_crs = xds.coordinate_system\n",
    "            else:\n",
    "                print('hello world')\n",
    "            \n",
    "            netcdf_var=xds[var_name]\n",
    "            \n",
    "            if(data_source == 'LIVNEHhistorical1915'):\n",
    "                netcdf_var.rio.set_crs('EPSG:4326', inplace=True)\n",
    "\n",
    "            final = netcdf_var.assign_coords(lon=(((netcdf_var.lon + 180) % 360) - 180))\n",
    "        \n",
    "            final.rio.set_spatial_dims(x_dim=\"lon\", y_dim=\"lat\")\n",
    "\n",
    "            newfilename = original_list[j][:-3]+'.tif' # append .tif instead of .nc\n",
    "            os.chdir('/home/jupyter-rouze')\n",
    "\n",
    "            if (to_clip == 'True'):\n",
    "                \n",
    "                lats = final.coords['lat'][:] \n",
    "                lons = final.coords['lon'][:]\n",
    "                # lat_bnds, lon_bnds = [38.6, 42.54], [-76.3, -74.23] # originall hard-coded\n",
    "                lat_bnds, lon_bnds = [bounds[0]-pad_factor, bounds[1]+pad_factor], [bounds[2]-pad_factor, bounds[3]+pad_factor]\n",
    "                \n",
    "                lat_inds = np.where((lats > lat_bnds[0]) & (lats < lat_bnds[1]))[0]\n",
    "                lon_inds = np.where((lons > lon_bnds[0]) & (lons < lon_bnds[1]))[0]\n",
    "                \n",
    "                subset_netcdf=final[:,lat_inds,lon_inds]\n",
    "                subset_netcdf.rio.set_spatial_dims(x_dim=\"lon\", y_dim=\"lat\")\n",
    "\n",
    "                local_file = 'in/temp/'+ original_list[0][-61:][:-3]+'.tif'\n",
    "\n",
    "                bucket = original_list[0][0:11]\n",
    "\n",
    "                bucket_filepath = original_list[0][12:]\n",
    "\n",
    "#                 os.getcwd()\n",
    "            \n",
    "                subset_netcdf.rio.to_raster(local_file)\n",
    "                \n",
    "#                 s3_push_delete_local(local_file, bucket, bucket_filepath)\n",
    "                \n",
    "            else:\n",
    "\n",
    "                final.rio.to_raster(newfilename, driver='GTiff')\n",
    "\n",
    "        else:\n",
    "            print('Hello world')\n",
    "            \n",
    "        \n",
    "#         fs.close(fobj)\n",
    "#     final_list.append(rio.open(fs.open(local_file)))\n",
    "    final_list.append(rio.open(local_file))\n",
    "        \n",
    "    return final_list, local_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grepfxn(pattern,files):\n",
    "    # Purpose: this function \n",
    "    precip_asc_df2=pd.DataFrame(files)\n",
    "    idx_asc_in2 = []\n",
    "    for i, precipfile in precip_asc_df2.iterrows():\n",
    "        val = re.findall(pattern, precipfile.iloc[0])\n",
    "        if len(val) > 0:\n",
    "            idx_asc_in2.append(i)\n",
    "            \n",
    "    ascfileround2 = [files[i] for i in idx_asc_in2]\n",
    "    return ascfileround2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "def s3_push_delete_local(local_file, bucket, bucket_filepath):\n",
    "        \"\"\"\n",
    "        This function will move the model outputs from a local folder to a cloud bucket.\n",
    "        :param local_file: path the the local geo file\n",
    "        :param outpath: path of a directory to be created in the cloud bucket\n",
    "        :param bucket: name of the cloud bucket = 'dev-et-data'\n",
    "        :param bucket_folder: \"folder\" in cloud bucket  = 'v1DRB_outputs'\n",
    "        :return:\n",
    "        \"\"\"\n",
    "\n",
    "        s3 = boto3.client('s3')\n",
    "        with open(local_file, \"rb\") as f:\n",
    "            print(bucket, bucket_filepath)\n",
    "            s3.upload_fileobj(f, bucket, bucket_filepath)\n",
    "        os.remove(local_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to get unique values \n",
    "def unique(list1): \n",
    "  \n",
    "    # intilize a null list \n",
    "    unique_list = [] \n",
    "      \n",
    "    # traverse for all elements \n",
    "    for x in list1: \n",
    "        # check if exists in unique_list or not \n",
    "        if x not in unique_list: \n",
    "            unique_list.append(x) \n",
    "\n",
    "    return(unique_list)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample_raster_write(raster, name,scale=0.5):\n",
    "    t = raster.transform\n",
    "\n",
    "    # rescale the metadata\n",
    "    transform = Affine(t.a / scale, t.b, t.c, t.d, t.e / scale, t.f)\n",
    "    height = int(raster.height * scale)\n",
    "    width = int(raster.width * scale)\n",
    "\n",
    "    profile = raster.profile\n",
    "    profile.update(transform=transform, driver='GTiff', height=height, width=width)\n",
    "\n",
    "    data = raster.read(1)\n",
    "    \n",
    "    with rio.open(name, 'w', **profile) as dst:\n",
    "        dst.write(data, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reproject_raster(src_filename, match_filename,dst_filename):\n",
    "    \n",
    "    from osgeo import gdal, gdalconst\n",
    "    \n",
    "    # Source\n",
    "    src = gdal.Open(src_filename, gdalconst.GA_ReadOnly)\n",
    "    src_proj = src.GetProjection()\n",
    "    src_geotrans = src.GetGeoTransform()\n",
    "    \n",
    "    # We want a section of source that matches this:\n",
    "    match_ds = gdal.Open(match_filename, gdalconst.GA_ReadOnly)\n",
    "    match_proj = match_ds.GetProjection()\n",
    "    match_geotrans = match_ds.GetGeoTransform()\n",
    "    \n",
    "    wide = match_ds.RasterXSize\n",
    "    high = match_ds.RasterYSize\n",
    "    \n",
    "    # Output / destination\n",
    "    dst = gdal.GetDriverByName('GTiff').Create(dst_filename, wide, high, 1, gdalconst.GDT_Float32)\n",
    "    dst.SetGeoTransform( match_geotrans )\n",
    "    dst.SetProjection( match_proj)\n",
    "    \n",
    "    # Do the work\n",
    "    gdal.ReprojectImage(src, dst, src_proj, match_proj, gdalconst.GRA_Bilinear)\n",
    "    \n",
    "    del dst # Flush"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rastermath(ensemble_list, iteration):\n",
    "    \n",
    "    # Purpose: To calculate the mean across X ensembles for each ith pixel\n",
    "    \n",
    "    # Returns a tuple with the first element the array, and the second the metadata of the the geoTiff file\n",
    "    \n",
    "    array_list=[]\n",
    "\n",
    "    for j in range(0, len(ensemble_list)):\n",
    "        dataset = ensemble_list[j]\n",
    "        \n",
    "        raster_array_read = dataset.read(iteration+1, masked=False) # fixed from masked=False to masked=True on 8/17/2020 - this applied to the gridMET data\n",
    "        raster_meta = dataset.profile\n",
    "        \n",
    "#         raster_array_rot = np.rot90(raster_array_read,2)\n",
    "#         raster_array_flip = np.flip(raster_array_rot,1)\n",
    "        \n",
    "#         array_list.append(raster_array_flip)\n",
    "        array_list.append(raster_array_read)\n",
    "\n",
    "    if(len(array_list) > 1):\n",
    "        # Hard coded here by bands, might need to update this to adapt to any number of bands\n",
    "        if(len(array_list) == 6):\n",
    "            array_mean = np.mean( np.array([ array_list[0], array_list[1],array_list[2],array_list[3],array_list[4],array_list[5]]), axis=0 )\n",
    "        elif len(array_list) == 5:\n",
    "            array_mean = np.mean( np.array([ array_list[0], array_list[1],array_list[2],array_list[3],array_list[4]]), axis=0 )\n",
    "        elif len(array_list) == 4:\n",
    "            array_mean = np.mean( np.array([ array_list[0], array_list[1],array_list[2],array_list[3]]), axis=0 )\n",
    "        elif len(array_list) == 3:\n",
    "            array_mean = np.mean( np.array([ array_list[0], array_list[1],array_list[2] ]), axis=0 )\n",
    "        else:\n",
    "            array_mean = np.mean( np.array([ array_list[0], array_list[1]]), axis=0 )\n",
    "    else:\n",
    "        array_mean = array_list[0]\n",
    "        \n",
    "    return array_mean, raster_meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_geotiff(data,meta,var_name,doy,year,folder):\n",
    "    \n",
    "    # Now we need to convert all of these arrays back to rasterio geoTIFFs\n",
    "    \n",
    "    os.chdir(folder+'/'+var_name)\n",
    "    \n",
    "    filename = var_name +'_' + str(year) +  str(doy).zfill(3)+'.tif'\n",
    "    with rio.open(filename, 'w', **meta) as dst:\n",
    "        dst.write(data, 1)\n",
    "        \n",
    "    return filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ET0_PM:\n",
    "    \n",
    "    def __init__(self, inputs, ET0_method,ET0_winddat,ET0_crop, constants):\n",
    "        \n",
    "        self.precipitation = inputs[0]\n",
    "        self.downwelling_radiation = inputs[1]\n",
    "        self.airtemperature_min = inputs[2]\n",
    "        self.airtemperature_max = inputs[3]\n",
    "        self.windspeed_2m = inputs[4]\n",
    "        self.vapor_saturated = inputs[5]\n",
    "        self.vapor_actual = inputs[6]\n",
    "        self.elevation = inputs[7]\n",
    "        self.latitude = inputs[8]\n",
    "        self.dayofyear = inputs[9]\n",
    "        \n",
    "        self.ET0_method = ET0_method\n",
    "        self.ET0_winddat = ET0_winddat\n",
    "        self.ET0_crop = ET0_crop\n",
    "        \n",
    "        self.alpha=constants[0]\n",
    "        self.z0 = constants[1]\n",
    "\n",
    "    \n",
    "    lambda_const = 2.45\n",
    "    Gsc = 0.082\n",
    "    G = 0\n",
    "    sigma = 4.903*10**-9\n",
    "\n",
    "    def incoming_shortwave(self):\n",
    "        \n",
    "#         self.R_s_in = self.downwelling_radiation*10**-6 # get into MJ m-2 day-1 (instead of J m-2 day-1)\n",
    "        # self.Ta = (self.airtemperature_max+ self.airtemperature_min) / 2 - 273.15\n",
    "        # self.delta = 4098 * (0.6108 * np.exp((17.27 * self.Ta)/(self.Ta+237.3))) / ((self.Ta + 237.3)**2) # slope of vapour pressure curve (S2.4), kPa C-1, http://www.fao.org/3/X0490E/x0490e07.htm\n",
    "        self.R_s_in = self.downwelling_radiation*10**-6 * 3600 * 24 # From W m-2 to MJ m-2 day-1\n",
    "        \n",
    "    def outgoing_shortwave(self):\n",
    "        \n",
    "        self.R_s_out = self.alpha * self.R_s_in\n",
    "\n",
    "    def outgoing_longwave(self):\n",
    "        \n",
    "        self.Ta = (self.airtemperature_max+ self.airtemperature_min) / 2 - 273.15  # Equation S2.1 in Tom McMahon's HESS 2013 paper, which in turn was based on Equation 9 in Allen et al, 1998.\n",
    "        self.P = 101.3 * ((293 - 0.0065 * self.elevation) / 293)**5.26 # atmospheric pressure (S2.10), in kPa\n",
    "        self.delta = 4098 * (0.6108 * np.exp((17.27 * self.Ta)/(self.Ta+237.3))) / ((self.Ta + 237.3)**2) # slope of vapour pressure curve (S2.4), kPa C-1, http://www.fao.org/3/X0490E/x0490e07.htm\n",
    "        self.gamma = 0.00163 * self.P / self.lambda_const # psychrometric constant (S2.9) kPa C-1\n",
    "        self.d_r2 = 1 + 0.033*np.cos(2*math.pi/365 * self.dayofyear) # dr is the inverse relative distance Earth-Sun (S3.6)\n",
    "        self.delta2 = 0.409 * np.sin(2*math.pi/365 * self.dayofyear - 1.39) # solar dedication (S3.7)\n",
    "        self.w_s = np.arccos(-np.tan(self.latitude) * np.tan(self.delta2))  # sunset hour angle (S3.8)\n",
    "        self.N = 24/math.pi * self.w_s # calculating daily values\n",
    "        self.R_a = (1440/math.pi) * self.d_r2 * self.Gsc * (self.w_s * np.sin(self.latitude) * np.sin(self.delta2) + np.cos(self.latitude) * np.cos(self.delta2) * np.sin(self.w_s)) # extraterristrial radiation (S3.5)\n",
    "        self.R_so = (0.75 + (2*10**-5) * self.elevation) * self.R_a # clear sky radiation (S3.4)\n",
    "        self.R_nl = self.sigma * ((self.airtemperature_max)**4 + (self.airtemperature_min)**4)/2 *(0.34 - 0.14 * np.sqrt(self.vapor_actual)) * (1.35 * self.R_s_in / self.R_so - 0.35) # estimated net outgoing longwave radiation (S3.3)\n",
    "\n",
    "    def net_radiation(self):\n",
    "        \n",
    "        self.R_nsg =  self.R_s_in - self.R_s_out# net incoming shortwave radiation (S3.2)\n",
    "        self.R_ng = self.R_nsg - self.R_nl # net radiation (S3.1)\n",
    "        \n",
    "    def ET0_calcs(self):\n",
    "\n",
    "        if (self.ET0_crop == \"short\"):\n",
    "            \n",
    "            self.r_s = 70 # will not be used for calculation - just informative\n",
    "            self.CH = 0.12 # will not be used for calculation - just informative\n",
    "          \n",
    "            # below in units of mm day-1, Final computation below\n",
    "#             self.ET0_Daily_numerator = ( (0.408 * self.delta * (self.R_ng - self.G)) + \n",
    "#                                         (self.gamma * (900/(self.Ta + 273.2)) * self.windspeed_2m * \n",
    "#                                          (self.vapor_saturated - self.vapor_actual) ) ) \n",
    "             \n",
    "#             self.ET0_Daily_denominator = (self.delta + self.gamma * (1 + 0.34*self.windspeed_2m )) # FAO-56 reference crop evapotranspiration from short grass (S5.18)\n",
    "#             self.ET0_Daily = self.ET0_Daily_numerator/ self.ET0_Daily_denominator\n",
    "            self.ET0_Daily_numerator1 = ( (0.408 * self.delta * (self.R_ng - self.G))) \n",
    "            \n",
    "            self.ET0_Daily_numerator2 =  (self.gamma * (900/(self.Ta + 273.2)) * \\\n",
    "                                          self.windspeed_2m * (self.vapor_saturated -\\\n",
    "                                                               self.vapor_actual) )  \n",
    "             \n",
    "            self.ET0_Daily_denominator = (self.delta + self.gamma * (1 + 0.34*self.windspeed_2m )) # FAO-56 reference crop evapotranspiration from short grass (S5.18)\n",
    "            self.ET0_Daily = (self.ET0_Daily_numerator1+self.ET0_Daily_numerator2)/ self.ET0_Daily_denominator\n",
    "        \n",
    "        else:\n",
    "            \n",
    "            self.r_s = 45 # will not be used for calculation - just informative\n",
    "            self.CH = 0.50 # will not be used for calculation - just informative\n",
    "            self.ET0_Daily_numerator = (0.408 * self.delta * (self.R_ng - self.G) + \n",
    "                                        (self.gamma * 1600 * self.u2 * (self.vs - self.va))/(self.Ta + 273))\n",
    "            self.ET0_Daily_denominator = (self.delta + self.gamma * (1 + 0.38*self.u2))\n",
    "            self.ET0_Daily = self.ET0_Daily_numerator / self.ET0_Daily_denominator # ASCE-EWRI standardised Penman-Monteith for long grass (S5.19)\n",
    "        \n",
    "        self.ET0_Daily = np.round(self.ET0_Daily, 2)\n",
    "        self.ET0_Daily[self.ET0_Daily < 0] = 0\n",
    "        \n",
    "        return self.ET0_Daily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_raster_inmem(raster, scale=0.5):\n",
    "    t = raster.transform\n",
    "\n",
    "    # rescale the metadata\n",
    "    transform = Affine(t.a / scale, t.b, t.c, t.d, t.e / scale, t.f)\n",
    "    height = int(raster.height * scale)\n",
    "    width = int(raster.width * scale)\n",
    "\n",
    "    profile = raster.profile\n",
    "    profile.update(transform=transform, driver='GTiff', height=height, width=width)\n",
    "\n",
    "    data = raster.read( # Note changed order of indexes, arrays are band, row, col order not row, col, band\n",
    "            out_shape=(raster.count, height, width),\n",
    "            resampling=Resampling.bilinear)\n",
    "\n",
    "    with MemoryFile() as memfile:\n",
    "        with memfile.open(**profile) as dataset: # Open as DatasetWriter\n",
    "            dataset.write(data)\n",
    "            del data\n",
    "\n",
    "        with memfile.open() as dataset:  # Reopen as DatasetReader\n",
    "            return dataset, profile  # Note yield not return     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def atmospheric_pressure(elevation):\n",
    "    # https://en.wikipedia.org/wiki/Barometric_formula\n",
    "    Pb = 101325 # Pa\n",
    "    g0 = 9.80665\n",
    "    M = 0.0289644\n",
    "    hb = 0\n",
    "    R = 8.3144598\n",
    "    Tb = 288.15\n",
    "    Lb = -0.0065 \n",
    "    \n",
    "    # https://www.mide.com/air-pressure-at-altitude-calculator\n",
    "    # https://en.wikipedia.org/wiki/Atmospheric_pressure\n",
    "    P = Pb * (1 + Lb/Tb*(elevation-hb))**(-(g0*M)/(R*Lb))\n",
    "  \n",
    "    return(P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relative_fromspecific(pressure, temperature, specifichumidity):\n",
    "    # https://earthscience.stackexchange.com/questions/2360/how-do-i-convert-specific-humidity-to-relative-humidity\n",
    "    test=(17.67*(temperature - 273.16))/(temperature - 29.65)\n",
    "    rh = 0.263 * pressure * specifichumidity * np.exp(test)**-1\n",
    "    \n",
    "    return(rh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
