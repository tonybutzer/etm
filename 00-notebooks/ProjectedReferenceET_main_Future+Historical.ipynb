{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code ported from laptop onto 10.12.68.72 starting on 8/24/2020 (Gregory Rouze)\n",
    "\n",
    "# To-do: \n",
    "# 1) need to separate user functions and main code - I have done this successfully in the offline version, but I'm having a\n",
    "# little more trouble in the cloud version\n",
    "# 2) Add comments on putpose of individual user functions\n",
    "# 3) Run a long term experiment this weekend to see if I run into VPN problems (processing will take a while)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''Import relevant packages, functions, and user functions used in this reference ET derivation'''\n",
    "\n",
    "import boto3\n",
    "from contextlib import contextmanager \n",
    "import earthpy.spatial as es\n",
    "import fsspec\n",
    "from math import e\n",
    "import rasterio as rio\n",
    "import xarray as xr\n",
    "from osgeo.gdalnumeric import *\n",
    "from osgeo.gdalconst import *\n",
    "import os\n",
    "from osgeo import gdal, osr, gdal_array, gdalconst\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import sys\n",
    "import ogr\n",
    "from rasterio import Affine, MemoryFile\n",
    "from rasterio.enums import Resampling\n",
    "import rioxarray\n",
    "from shapely.geometry import Point, Polygon\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import box\n",
    "from fiona.crs import from_epsg\n",
    "from matplotlib import pyplot as plt\n",
    "from rasterio.plot import plotting_extent\n",
    "import earthpy.plot as ep\n",
    "import math\n",
    "from itertools import chain\n",
    "from ipynb.fs.full.ProjectedReferenceET_Classes_Functions import ET0_PM, aggregate_raster_inmem, resample_raster_write, \\\n",
    "reproject_raster, grepfxn, rastermath, lapply_brick, write_geotiff, atmospheric_pressure, relative_fromspecific, unique, s3_push_delete_local\n",
    "import boto3\n",
    "# unique # test the import worked correctly\n",
    "\n",
    "os.getcwd() # home/jupyter-rouze' is root or default path\n",
    "os.chdir('/home/jupyter-rouze')\n",
    "# os.chdir('in/temp')\n",
    "# os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Read configuration file and parse out the inputs line by line'''\n",
    "\n",
    "configurationfile = 'configurationfile_referenceET_test_future.ini'\n",
    "# configurationfile = 'configurationfile_referenceET_test_historical.ini'\n",
    "\n",
    "with open(configurationfile) as f:\n",
    "    data = {}\n",
    "    for line in f:\n",
    "        key, value = line.strip().split(' = ')\n",
    "        data[key] = value\n",
    "        \n",
    "# print(data)\n",
    "\n",
    "model_files = data['model_files']\n",
    "data_source = data['data_source']\n",
    "output_folder = data['output_folder']\n",
    "elevfile = data['elevfile']\n",
    "tiffolder = data['tiffolder']\n",
    "ET0_method = data['ET0_method']\n",
    "ET0_winddat = data['ET0_winddat']\n",
    "ET0_crop = data['ET0_crop']\n",
    "to_clip = data['to_clip']\n",
    "model = data['model']\n",
    "northmost = float(data['northmost'])\n",
    "southmost = float(data['southmost'])\n",
    "westmost = float(data['westmost'])\n",
    "eastmost = float(data['eastmost'])\n",
    "pad_factor = float(data['pad_factor'])\n",
    "rcp_source = data['rcp_source']\n",
    "MACA_start_bucket = data['MACA_start_bucket']\n",
    "\n",
    "'''This is needed to retrieve the netCDF files from the dev-et-data AWS bucket'''\n",
    "# os.chdir(model_files)\n",
    "fs = fsspec.filesystem(model_files, anon=False, requester_pays=True)\n",
    "\n",
    "# list all of the inputs - assumption: this folder only contains input variables.\n",
    "# model_filesos.listdir()\n",
    "# print(data_source)\n",
    "# all_files = fs.find('dev-et-data/in/DelawareRiverBasin/')\n",
    "all_files = fs.find(MACA_start_bucket)\n",
    "print(data)\n",
    "# print(data['elevfile'])\n",
    "\n",
    "print(all_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THE CODE BELOW IS PARSED FROM THE CONDIITION WHEN DEALING WITH METDATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split models apart that are to be used for ensemble averaging\n",
    "models_parsed = [x.strip() for x in model.split(',')]\n",
    "\n",
    "# Whittle down the number of files if the folder contains both rcp 4.5 and rcp 8.5 files\n",
    "# Right now, the code can only handle one model of METDATA output (8/21/2020)\n",
    "rcp_all_files = [grepfxn(rcp_source,all_files)][0]\n",
    "# historical_all_files = [grepfxn('historical',all_files)][0]\n",
    "# print(rcp_all_files)\n",
    "# print(historical_all_files)\n",
    "\n",
    "# Iterate the files by each each specified model\n",
    "models_list=[]\n",
    "for i in range(len(models_parsed)):\n",
    "    model_files_loop = [grepfxn(models_parsed[i],rcp_all_files)][0]\n",
    "    models_list.append(model_files_loop)\n",
    "        \n",
    "# Flatten series of lists into one list\n",
    "rcp_all_files = list(chain(*models_list))\n",
    "\n",
    "print(rcp_all_files)\n",
    "\n",
    "# # Iterate the files by each each specified model\n",
    "# models_list=[]\n",
    "# for i in range(len(models_parsed)):\n",
    "#     model_files_loop = [grepfxn(models_parsed[i],historical_all_files)][0]\n",
    "#     models_list.append(model_files_loop)\n",
    "        \n",
    "# # Flatten series of lists into one list\n",
    "# historical_all_files = list(chain(*models_list))\n",
    "\n",
    "# print(historical_all_files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Find and compile the year blocks into a list\n",
    "dfis=[]\n",
    "# for out in historical_all_files+rcp_all_files:\n",
    "for out in rcp_all_files:\n",
    "    a=out.split('_')\n",
    "    dfi = a[5]+'_'+a[6]\n",
    "    dfis.append(dfi)\n",
    "\n",
    "# print(dfis)\n",
    "    \n",
    "# Distill the above list into unique year blocks, as there will be duplicates from \n",
    "# multiple climate inputs\n",
    "year_all=unique(dfis);print(year_all)\n",
    "\n",
    "# For prototyping only\n",
    "year_block=0\n",
    "print(year_all[year_block])\n",
    "# year_all=year_all[1];print(year_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code is piecemeal from that within the for loop below\n",
    "# it was more for me and prototyping within the cloud, so that \n",
    "# the variables are the same as those when I created this code offline \n",
    "# in other words, I wanted to ensure consistency (Gregory Rouze) - 9/10/2020\n",
    "\n",
    "# print(rcp_all_files)\n",
    "\n",
    "# print(year_all[year_block])\n",
    "\n",
    "# year_block=0\n",
    "# year_block_files = grepfxn(year_all[year_block],rcp_all_files)\n",
    "# print(year_block_files)\n",
    "\n",
    "# year_block=1\n",
    "# year_block_files = grepfxn(year_all[year_block],rcp_all_files)\n",
    "# print(year_block_files)\n",
    "\n",
    "# bounds=[southmost,northmost,westmost,eastmost]\n",
    "# rcp_pr = lapply_brick(grepfxn(\"pr\",year_block_files), 'precipitation', model_files,tiffolder,data_source,to_clip=to_clip,bounds=bounds,pad_factor=pad_factor)\n",
    "\n",
    "# print(rcp_pr)\n",
    "\n",
    "# # Skip 2006-2010 for now because of corrupted files\n",
    "# # year_all2=year_all[1:] # future\n",
    "# year_all2=year_all[0:] # historical\n",
    "# print(year_all2)\n",
    "\n",
    "# year_block_files = grepfxn(year_all[year_block],rcp_all_files)\n",
    "# print(year_block_files)\n",
    "\n",
    "# print(rcp_pr[0][0].count)\n",
    "# print(doy_loop)\n",
    "# year_loop\n",
    "\n",
    "# print(year_all)\n",
    "# print(year_block)\n",
    "# print(year_all[3:4])\n",
    "# year_all2=year_all[11:]\n",
    "# print(range(1,len(year_all2)))\n",
    "# print(year_all2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# year_all2=year_all[3:4] # for 1965-1969 historical\n",
    "# year_all2=year_all[0:1] # for 2006-2010 only\n",
    "# year_all2=year_all[11:] # for 2046-2100\n",
    "# year_all2=year_all[3:]\n",
    "# for year_block in range(1,len(year_all2)): # for future (for now, will go back and get 2006-2010 and 1950-1954)\n",
    "\n",
    "# This is the meat of the code: I kept year_all2 above because I had to reprocess some years because of\n",
    "# previously corrupt data in the data bucket (I think because of the mini-pangeo crash from earlier)\n",
    "\n",
    "for year_block in range(0,len(year_all)): # for future (for now, will go back and get 2006-2010 and 1950-1954)\n",
    "    # year_block_files = grepfxn(year_all[year_block],historical_all_files+rcp_all_files);print(year_block_files)\n",
    "    year_block_files = grepfxn(year_all[year_block],rcp_all_files)\n",
    "    \n",
    "    print(year_block_files)\n",
    "\n",
    "    bounds=[southmost,northmost,westmost,eastmost]\n",
    "\n",
    "    rcp_pr = lapply_brick(grepfxn(\"pr\",year_block_files), 'precipitation', model_files,tiffolder,data_source,to_clip=to_clip,bounds=bounds,pad_factor=pad_factor)\n",
    "    # downwelling shortwave radiation\n",
    "    rcp_rsds = lapply_brick(grepfxn(\"rsds\",year_block_files), 'surface_downwelling_shortwave_flux_in_air', model_files,tiffolder,data_source,to_clip=to_clip,bounds=bounds,pad_factor=pad_factor)\n",
    "    # maximum air temperature\n",
    "    rcp_tasmax = lapply_brick(grepfxn(\"tasmax\",year_block_files), 'air_temperature', model_files,tiffolder,data_source,to_clip=to_clip,bounds=bounds,pad_factor=pad_factor)\n",
    "    # minimum air temperature\n",
    "    rcp_tasmin = lapply_brick(grepfxn(\"tasmin\",year_block_files), 'air_temperature', model_files,tiffolder,data_source,to_clip=to_clip,bounds=bounds,pad_factor=pad_factor)\n",
    "    # Now repeat above for the rcp 8.5 model outputs below\n",
    "\n",
    "    if(data_source == 'METDATA'):\n",
    "\n",
    "        rcp_uas = lapply_brick(grepfxn(\"uas\",year_block_files), 'eastward_wind', model_files,tiffolder,data_source,to_clip=to_clip,bounds=bounds,pad_factor=pad_factor)\n",
    "\n",
    "        rcp_vas = lapply_brick(grepfxn(\"vas\",year_block_files), 'northward_wind', model_files,tiffolder,data_source,to_clip=to_clip,bounds=bounds,pad_factor=pad_factor)\n",
    "\n",
    "        rcp_rhsmax = lapply_brick(grepfxn(\"rhsmax\",year_block_files), 'relative_humidity', model_files,tiffolder,data_source,to_clip=to_clip,bounds=bounds,pad_factor=pad_factor)\n",
    "\n",
    "        rcp_rhsmin = lapply_brick(grepfxn(\"rhsmin\",year_block_files), 'relative_humidity', model_files,tiffolder,data_source,to_clip=to_clip,bounds=bounds,pad_factor=pad_factor)\n",
    "\n",
    "        # The section below is meant to convert netCDF files into geoTIFFs\n",
    "        \n",
    "    src = rio.open(elevfile)\n",
    "    # elevation_full_aggregate = aggregate_raster_inmem(src,scale=0.5)\n",
    "    aggoutput_name='elevation_aggregated.tif'\n",
    "    \n",
    "    resample_raster_write(src, name= aggoutput_name,scale=0.5)\n",
    "    \n",
    "    dst_filename='elevation_aggregated_resampled.tif'\n",
    "    match_filename=rcp_pr[0][0].name\n",
    "    reproject_raster(aggoutput_name, match_filename,dst_filename)\n",
    "    \n",
    "    elevation_array=rio.open(dst_filename).read(1)\n",
    "\n",
    "    # from datetime import datetime - will need to update to make start/end adaptive (7/28/2020)\n",
    "#     start_year=year_all[year_block][0:4]\n",
    "#     end_year=year_all[year_block][5:9]\n",
    "    start_year=year_all[year_block][0:4]\n",
    "    end_year=year_all[year_block][5:9]\n",
    "\n",
    "    start=start_year+'-01-01'\n",
    "    end=end_year+'-12-31'\n",
    "    datetimes = pd.date_range(start=start,end=end)\n",
    "    i=10\n",
    "    \n",
    "    for i in range(0,rcp_pr[0][0].count):\n",
    "\n",
    "        doy_loop = pd.Period(datetimes[i],freq='D').dayofyear\n",
    "        year_loop = pd.Period(datetimes[i],freq='D').year\n",
    "\n",
    "        # step 1: extract ith band from the raster stack\n",
    "        # step 2: stack those ith bands together\n",
    "        # step 3: do raster mean math from step 2\n",
    "        pr_stack=[]\n",
    "\n",
    "        # Purpose: create stacks of variables individually - this is like brick in R\n",
    "        pr_ensemble = []\n",
    "        rsds_ensemble = []\n",
    "        tasmax_ensemble = []\n",
    "        tasmin_ensemble = []\n",
    "\n",
    "        j = 0\n",
    "\n",
    "        # should be 1 array for each variable (mean of x ensembles for a given doy)\n",
    "        # rcp_pr[0][0].read(1, masked=False).shape\n",
    "        rcp_pr_doy = rastermath(rcp_pr[0], i)\n",
    "        rcp_rsds_doy = rastermath(rcp_rsds[0], i)\n",
    "        rcp_tasmax_doy = rastermath(rcp_tasmax[0], i)\n",
    "        rcp_tasmin_doy = rastermath(rcp_tasmin[0], i)\n",
    "\n",
    "        dims = np.shape(rcp_pr_doy[0])\n",
    "        rows = dims[0]\n",
    "        cols = dims[1]\n",
    "        constant_1_dat = np.full((rows,cols), 17.27)\n",
    "        constant_2_dat = np.full((rows,cols), 0.6108)\n",
    "        constant_3_dat = np.full((rows,cols), 273.15)\n",
    "        constant_4_dat = np.full((rows,cols), 237.3)\n",
    "\n",
    "        rcp_vs_tmax_array = constant_2_dat * np.exp(constant_1_dat * (rcp_tasmax_doy[0]-constant_3_dat) / ( (rcp_tasmax_doy[0]-constant_3_dat) + constant_4_dat)) # Equation S2.5\n",
    "        rcp_vs_tmin_array = constant_2_dat * np.exp(constant_1_dat * (rcp_tasmin_doy[0]-constant_3_dat) / ( (rcp_tasmin_doy[0]-constant_3_dat) + constant_4_dat)) # Equation S2.5\n",
    "        rcp_saturatedvapor_doy = (rcp_vs_tmax_array + rcp_vs_tmin_array)/2 \n",
    "\n",
    "        if(data_source == 'METDATA'): # line 180 from R script\n",
    "\n",
    "            # All of these are arrays by the way\n",
    "            rcp_rhsmax_doy = rastermath(rcp_rhsmax[0], i)\n",
    "            rcp_rhsmin_doy = rastermath(rcp_rhsmin[0], i)\n",
    "            rcp_uas_doy = rastermath(rcp_uas[0], i)\n",
    "            rcp_vas_doy = rastermath(rcp_vas[0], i)\n",
    "\n",
    "            # was below are just arrays, not metadata profiles\n",
    "            rcp_was_doy_10m = np.sqrt(rcp_uas_doy[0]**2 + rcp_vas_doy[0]**2 )\n",
    "\n",
    "            rcp_actualvapor_doy = (rcp_vs_tmin_array * rcp_rhsmax_doy[0]/100 + rcp_vs_tmax_array * rcp_rhsmin_doy[0]/100)/2\n",
    "            \n",
    "#             rcp_actualvapor_doy = rcp_vs_tmin_array\n",
    "            \n",
    "#         elif (data_source == \"Future_LIVNEH\"):\n",
    "\n",
    "#             pressure = atmospheric_pressure(elevation_array)\n",
    "\n",
    "#             rcp_huss_doy = rastermath(rcp_huss[0], i)\n",
    "\n",
    "#             rcp_was_doy_10m = rastermath(rcp_was[0], i)\n",
    "\n",
    "#             rcp_tasmean_doy = (rcp_tasmax_doy[0] + rcp_tasmin_doy[0])/2\n",
    "\n",
    "#             rcp_rhmean_doy = relative_fromspecific(pressure,rcp_tasmean_doy, rcp_huss_doy[0])\n",
    "\n",
    "#             rcp_actualvapor_doy = rcp_rhmean_doy / 100 * rcp_saturatedvapor_doy\n",
    "\n",
    "        da = xr.open_rasterio(rcp_pr[1])\n",
    "        da_r = rio.open(rcp_pr[1])\n",
    "        ny, nx = len(da['y']), len(da['x'])\n",
    "        longitude_array, latitude_array = np.meshgrid(da['x'], da['y'])\n",
    "\n",
    "        latitude_array_rad = latitude_array * (math.pi/180)\n",
    "\n",
    "        # Wind speed at 2 meters\n",
    "        z = np.full((rows,cols), 10)\n",
    "        array_487 = np.full((rows,cols), 4.87)\n",
    "        array_678 = np.full((rows,cols), 67.8)\n",
    "        array_542 = np.full((rows,cols), 5.42)\n",
    "\n",
    "        if (data_source == 'METDATA'):\n",
    "            rcp_was_doy_2m = rcp_was_doy_10m * array_487 / np.log(array_678*z - array_542) # Equation S5.20 for PET formulations other than Penman\n",
    "        else:\n",
    "            rcp_was_doy_2m = rcp_was_doy_10m[0] * array_487 / np.log(array_678*z - array_542) # Equation S5.20 for PET formulations other than Penman\n",
    "\n",
    "        doy_array = np.full((rows,cols), i+1)\n",
    "\n",
    "        rcp_pr_doy[1]['count']=1\n",
    "        rcp_tasmin_doy[1]['count']=1\n",
    "        rcp_tasmax_doy[1]['count']=1\n",
    "\n",
    "        # To-do: go ahead and developed ET0 directly as opposed to the R implementation(7/29)\n",
    "\n",
    "        ET0_inputarrays_rcp = [rcp_pr_doy[0], rcp_rsds_doy[0], rcp_tasmin_doy[0],\n",
    "                                     rcp_tasmax_doy[0],rcp_was_doy_2m,rcp_saturatedvapor_doy,\n",
    "                                     rcp_actualvapor_doy,elevation_array,latitude_array_rad,doy_array]\n",
    "\n",
    "        # NameError: name 'ET0_method' is not defined\n",
    "        if ET0_method  == \"yes\":\n",
    "          if ET0_crop != \"short\" and ET0_crop != \"tall\":\n",
    "            stop(\"Please enter 'short' or 'tall' for the desired reference crop type\")\n",
    "          else:\n",
    "            alpha = 0.23 # albedo for both short and tall crop\n",
    "            if (ET0_crop == \"short\"):\n",
    "              z0 = 0.02 # roughness height for short grass\n",
    "            else:\n",
    "              z0 = 0.1 # roughness height for tall grass\n",
    "        else:\n",
    "            z0 = 0.02 # roughness height for short grass\n",
    "            alpha = 0.25 # semi-desert short grass - will not be used for calculation - just informative\n",
    "\n",
    "        constants=[alpha, z0]\n",
    "\n",
    "        ET0_rcp = ET0_PM(ET0_inputarrays_rcp,ET0_method,ET0_winddat,ET0_crop,constants)\n",
    "        ET0_rcp.incoming_shortwave()\n",
    "        ET0_rcp.outgoing_shortwave()\n",
    "        ET0_rcp.outgoing_longwave()\n",
    "        ET0_rcp.net_radiation()\n",
    "        ET0_rcp_array_from_class = ET0_rcp.ET0_calcs()\n",
    "        ET0_rcp_array_final = ET0_rcp_array_from_class.astype('float32')\n",
    "\n",
    "        rcp_pr_doy[1]['count']=1\n",
    "\n",
    "        os.chdir('/home/jupyter-rouze')\n",
    "        gTIFF_filename = write_geotiff(data=ET0_rcp_array_final,meta=rcp_pr_doy[1],var_name='reference_evapotranspiration',\n",
    "                                       doy=doy_loop,year=year_loop,folder=output_folder)\n",
    "\n",
    "        #         local_file = root + '/' + gTIFF_filename \n",
    "        local_file = output_folder+'/' + 'reference_evapotranspiration' + '/' + gTIFF_filename \n",
    "        bucket = 'dev-et-data'\n",
    "        #         bucket_filepath = 'in/DelawareRiverBasin/ETo/'+ gTIFF_filename \n",
    "\n",
    "#         if(os.path.isdir(str(year_loop))  == False):\n",
    "#             root = output_folder+'/' + 'reference_evapotranspiration' + '/' + str(year_loop)\n",
    "#             os.mkdir(root)\n",
    "#         else:\n",
    "#             root = output_folder+'/' + 'reference_evapotranspiration' + '/' + str(year_loop)\n",
    "\n",
    "        bucket_filepath = 'in/DelawareRiverBasin/ETo/'+ str(year_loop)  + '/' + gTIFF_filename \n",
    "#         local_file = output_file+'/reference'\n",
    "        \n",
    "        os.chdir('/home/jupyter-rouze')\n",
    "        s3_push_delete_local(local_file, bucket, bucket_filepath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The code below is trash code that is either not used in the for loop above, or \n",
    "# is piecemeal like above. this stuff below should be ignored for inspection purposes (Gregory Rouze, 9/10/2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(year_all2)\n",
    "print(year_all[year_block])\n",
    "print(end_year)\n",
    "print(datetimes)\n",
    "print(year_loop)\n",
    "print(gTIFF_filename)\n",
    "print(bucket_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        local_file = output_folder+'/' + 'reference_evapotranspiration' + '/' + gTIFF_filename \n",
    "        bucket = 'dev-et-data'\n",
    "        #         bucket_filepath = 'in/DelawareRiverBasin/ETo/'+ gTIFF_filename \n",
    "\n",
    "#         if(os.path.isdir(str(year_loop))  == False):\n",
    "#             root = output_folder+'/' + 'reference_evapotranspiration' + '/' + str(year_loop)\n",
    "#             os.mkdir(root)\n",
    "#         else:\n",
    "#             root = output_folder+'/' + 'reference_evapotranspiration' + '/' + str(year_loop)\n",
    "\n",
    "        bucket_filepath = 'in/DelawareRiverBasin/ETo/'+ str(year_loop)  + '/' + gTIFF_filename \n",
    "#         local_file = output_file+'/reference'\n",
    "\n",
    "print(local_file)\n",
    "print(bucket)\n",
    "print(bucket_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = output_folder+'/' + 'reference_evapotranspiration' + '/' + str(year_loop)\n",
    "print(root + '/' + gTIFF_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gTIFF_filename)\n",
    "print('in/DelawareRiverBasin/ETo/Daily/'+ gTIFF_filename )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To-do: Push these from local to aws s3 data bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('hello world')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for year_block in range(0,len(year_all)):\n",
    "# year_block_files = grepfxn(year_all[year_block],historical_all_files+rcp_all_files);print(year_block_files)\n",
    "year_block_files = grepfxn(year_all[year_block],rcp_all_files);print(year_block_files)\n",
    "\n",
    "bounds=[southmost,northmost,westmost,eastmost]\n",
    "\n",
    "rcp_pr = lapply_brick(grepfxn(\"pr\",year_block_files), 'precipitation', model_files,tiffolder,data_source,to_clip=to_clip,bounds=bounds,pad_factor=pad_factor)\n",
    "# downwelling shortwave radiation\n",
    "rcp_rsds = lapply_brick(grepfxn(\"rsds\",year_block_files), 'surface_downwelling_shortwave_flux_in_air', model_files,tiffolder,data_source,to_clip=to_clip,bounds=bounds,pad_factor=pad_factor)\n",
    "# maximum air temperature\n",
    "rcp_tasmax = lapply_brick(grepfxn(\"tasmax\",year_block_files), 'air_temperature', model_files,tiffolder,data_source,to_clip=to_clip,bounds=bounds,pad_factor=pad_factor)\n",
    "# minimum air temperature\n",
    "rcp_tasmin = lapply_brick(grepfxn(\"tasmin\",year_block_files), 'air_temperature', model_files,tiffolder,data_source,to_clip=to_clip,bounds=bounds,pad_factor=pad_factor)\n",
    "# Now repeat above for the rcp 8.5 model outputs below\n",
    "\n",
    "if(data_source == 'METDATA'):\n",
    "\n",
    "    rcp_uas = lapply_brick(grepfxn(\"uas\",year_block_files), 'eastward_wind', model_files,tiffolder,data_source,to_clip=to_clip,bounds=bounds,pad_factor=pad_factor)\n",
    "\n",
    "    rcp_vas = lapply_brick(grepfxn(\"vas\",year_block_files), 'northward_wind', model_files,tiffolder,data_source,to_clip=to_clip,bounds=bounds,pad_factor=pad_factor)\n",
    "\n",
    "    rcp_rhsmax = lapply_brick(grepfxn(\"rhsmax\",year_block_files), 'relative_humidity', model_files,tiffolder,data_source,to_clip=to_clip,bounds=bounds,pad_factor=pad_factor)\n",
    "\n",
    "    rcp_rhsmin = lapply_brick(grepfxn(\"rhsmin\",year_block_files), 'relative_humidity', model_files,tiffolder,data_source,to_clip=to_clip,bounds=bounds,pad_factor=pad_factor)\n",
    "\n",
    "    # The section below is meant to convert netCDF files into geoTIFFs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rcp_uas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = rio.open(elevfile)\n",
    "# elevation_full_aggregate = aggregate_raster_inmem(src,scale=0.5)\n",
    "aggoutput_name='elevation_aggregated.tif'\n",
    "print(src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resample_raster_write(src, name= aggoutput_name,scale=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dst_filename='elevation_aggregated_resampled.tif'\n",
    "match_filename=rcp_pr[0][0].name\n",
    "reproject_raster(aggoutput_name, match_filename,dst_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elevation_array=rio.open(dst_filename).read(1)\n",
    "\n",
    "# from datetime import datetime - will need to update to make start/end adaptive (7/28/2020)\n",
    "start_year=year_all[year_block][0:4]\n",
    "end_year=year_all[year_block][5:9]\n",
    "\n",
    "start=start_year+'-01-01'\n",
    "end=end_year+'-12-31'\n",
    "datetimes = pd.date_range(start=start,end=end)\n",
    "i=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rcp_pr[0][0])\n",
    "raster_array = rcp_pr[0][0].read(1, masked=False)\n",
    "\n",
    "et = np.rot90(raster_array,2)\n",
    "et = np.flip(et,1)\n",
    "\n",
    "c1 = plt.imshow(et)\n",
    "plt.colorbar(c1) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(0,rcp_pr[0][0].count):\n",
    "\n",
    "doy_loop = pd.Period(datetimes[i],freq='D').dayofyear\n",
    "year_loop = pd.Period(datetimes[i],freq='D').year\n",
    "\n",
    "# step 1: extract ith band from the raster stack\n",
    "# step 2: stack those ith bands together\n",
    "# step 3: do raster mean math from step 2\n",
    "pr_stack=[]\n",
    "\n",
    "# Purpose: create stacks of variables individually - this is like brick in R\n",
    "pr_ensemble = []\n",
    "rsds_ensemble = []\n",
    "tasmax_ensemble = []\n",
    "tasmin_ensemble = []\n",
    "\n",
    "j = 0\n",
    "\n",
    "# should be 1 array for each variable (mean of x ensembles for a given doy)\n",
    "# rcp_pr[0][0].read(1, masked=False).shape\n",
    "rcp_pr_doy = rastermath(rcp_pr[0], i)\n",
    "rcp_rsds_doy = rastermath(rcp_rsds[0], i)\n",
    "rcp_tasmax_doy = rastermath(rcp_tasmax[0], i)\n",
    "rcp_tasmin_doy = rastermath(rcp_tasmin[0], i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(rcp_tasmax_doy)\n",
    "c1 = plt.imshow(rcp_tasmax_doy[0])\n",
    "plt.colorbar(c1) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dims = np.shape(rcp_pr_doy[0])\n",
    "rows = dims[0]\n",
    "cols = dims[1]\n",
    "constant_1_dat = np.full((rows,cols), 17.27)\n",
    "constant_2_dat = np.full((rows,cols), 0.6108)\n",
    "constant_3_dat = np.full((rows,cols), 273.15)\n",
    "constant_4_dat = np.full((rows,cols), 237.3)\n",
    "\n",
    "rcp_vs_tmax_array = constant_2_dat * np.exp(constant_1_dat * (rcp_tasmax_doy[0]-constant_3_dat) / ( (rcp_tasmax_doy[0]-constant_3_dat) + constant_4_dat)) # Equation S2.5\n",
    "rcp_vs_tmin_array = constant_2_dat * np.exp(constant_1_dat * (rcp_tasmin_doy[0]-constant_3_dat) / ( (rcp_tasmin_doy[0]-constant_3_dat) + constant_4_dat)) # Equation S2.5\n",
    "rcp_saturatedvapor_doy = (rcp_vs_tmax_array + rcp_vs_tmin_array)/2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(data_source == 'METDATA'): # line 180 from R script\n",
    "\n",
    "    # All of these are arrays by the way\n",
    "    rcp_rhsmax_doy = rastermath(rcp_rhsmax[0], i)\n",
    "    rcp_rhsmin_doy = rastermath(rcp_rhsmin[0], i)\n",
    "    rcp_uas_doy = rastermath(rcp_uas[0], i)\n",
    "    rcp_vas_doy = rastermath(rcp_vas[0], i)\n",
    "\n",
    "    # was below are just arrays, not metadata profiles\n",
    "    rcp_was_doy_10m = np.sqrt(rcp_uas_doy[0]**2 + rcp_vas_doy[0]**2 )\n",
    "\n",
    "    rcp_actualvapor_doy = (rcp_vs_tmin_array * rcp_rhsmax_doy[0]/100 + rcp_vs_tmax_array * rcp_rhsmin_doy[0]/100)/2\n",
    "\n",
    "elif (data_source == \"Future_LIVNEH\"):\n",
    "\n",
    "    pressure = atmospheric_pressure(elevation_array)\n",
    "\n",
    "    rcp_huss_doy = rastermath(rcp_huss[0], i)\n",
    "\n",
    "    rcp_was_doy_10m = rastermath(rcp_was[0], i)\n",
    "\n",
    "    rcp_tasmean_doy = (rcp_tasmax_doy[0] + rcp_tasmin_doy[0])/2\n",
    "\n",
    "    rcp_rhmean_doy = relative_fromspecific(pressure,rcp_tasmean_doy, rcp_huss_doy[0])\n",
    "\n",
    "    rcp_actualvapor_doy = rcp_rhmean_doy / 100 * rcp_saturatedvapor_doy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcp_was_doy_10m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rcp_pr)\n",
    "xr.open_rasterio(rcp_pr[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the lon/lat coordinates with rasterio.warp.transform\n",
    "# fs = fsspec.filesystem('s3')\n",
    "# fobj = fs.open(original_list[j])\n",
    "# xds = xr.open_dataset(fobj)\n",
    "\n",
    "da = xr.open_rasterio(rcp_pr[1])\n",
    "da_r = rio.open(rcp_pr[1])\n",
    "ny, nx = len(da['y']), len(da['x'])\n",
    "longitude_array, latitude_array = np.meshgrid(da['x'], da['y'])\n",
    "\n",
    "latitude_array_rad = latitude_array * (math.pi/180)\n",
    "\n",
    "# Wind speed at 2 meters\n",
    "z = np.full((rows,cols), 10)\n",
    "array_487 = np.full((rows,cols), 4.87)\n",
    "array_678 = np.full((rows,cols), 67.8)\n",
    "array_542 = np.full((rows,cols), 5.42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (data_source == 'METDATA'):\n",
    "    rcp_was_doy_2m = rcp_was_doy_10m * array_487 / np.log(array_678*z - array_542) # Equation S5.20 for PET formulations other than Penman\n",
    "else:\n",
    "    rcp_was_doy_2m = rcp_was_doy_10m[0] * array_487 / np.log(array_678*z - array_542) # Equation S5.20 for PET formulations other than Penman\n",
    "\n",
    "doy_array = np.full((rows,cols), i+1)\n",
    "\n",
    "rcp_pr_doy[1]['count']=1\n",
    "rcp_tasmin_doy[1]['count']=1\n",
    "rcp_tasmax_doy[1]['count']=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# technically speaking, writing these arrays as geotiffs is optional (except precip), as technically only precip and ET0 are needed - however, they provide for good sanity checks.\n",
    "# write_geotiff(data=rcp_pr_doy[0],meta=rcp_pr_doy[1],var_name='precipitation',doy=doy_loop,year=year_loop,folder=output_folder)\n",
    "# write_geotiff(data=rcp_tasmin_doy[0],meta=rcp_tasmin_doy[1],var_name='airtemperature_min',doy=doy_loop,year=year_loop,folder=output_folder)\n",
    "# write_geotiff(data=rcp_tasmax_doy[0],meta=rcp_tasmax_doy[1],var_name='airtemperature_max',doy=doy_loop,year=year_loop,folder=output_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# To-do: go ahead and developed ET0 directly as opposed to the R implementation(7/29)\n",
    "\n",
    "ET0_inputarrays_rcp = [rcp_pr_doy[0], rcp_rsds_doy[0], rcp_tasmin_doy[0],\n",
    "                             rcp_tasmax_doy[0],rcp_was_doy_2m,rcp_saturatedvapor_doy,\n",
    "                             rcp_actualvapor_doy,elevation_array,latitude_array_rad,doy_array]\n",
    "\n",
    "# NameError: name 'ET0_method' is not defined\n",
    "if ET0_method  == \"yes\":\n",
    "  if ET0_crop != \"short\" and ET0_crop != \"tall\":\n",
    "    stop(\"Please enter 'short' or 'tall' for the desired reference crop type\")\n",
    "  else:\n",
    "    alpha = 0.23 # albedo for both short and tall crop\n",
    "    if (ET0_crop == \"short\"):\n",
    "      z0 = 0.02 # roughness height for short grass\n",
    "    else:\n",
    "      z0 = 0.1 # roughness height for tall grass\n",
    "else:\n",
    "    z0 = 0.02 # roughness height for short grass\n",
    "    alpha = 0.25 # semi-desert short grass - will not be used for calculation - just informative\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# print(ET0_inputarrays_rcp[1])\n",
    "test=ET0_inputarrays_rcp[1]\n",
    "print(test)\n",
    "c1 = plt.imshow(test)\n",
    "plt.colorbar(c1) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ET0_inputarrays_rcp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "constants=[alpha, z0]\n",
    "\n",
    "ET0_rcp = ET0_PM(ET0_inputarrays_rcp,ET0_method,ET0_winddat,ET0_crop,constants)\n",
    "ET0_rcp.incoming_shortwave()\n",
    "ET0_rcp.outgoing_shortwave()\n",
    "ET0_rcp.outgoing_longwave()\n",
    "ET0_rcp.net_radiation()\n",
    "ET0_rcp_array_from_class = ET0_rcp.ET0_calcs()\n",
    "ET0_rcp_array_final = ET0_rcp_array_from_class.astype('float32')\n",
    "\n",
    "rcp_pr_doy[1]['count']=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "type(ET0_rcp_array_final)\n",
    "import matplotlib.pyplot as plt\n",
    "c = plt.imshow(ET0_rcp_array_final,origin='bottom')\n",
    "plt.colorbar(c) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(os.getcwd())\n",
    "os.chdir('in')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/home/jupyter-rouze')\n",
    "write_geotiff(data=ET0_rcp_array_final,meta=rcp_pr_doy[1],var_name='reference_evapotranspiration',\n",
    "              doy=doy_loop,year=year_loop,folder=output_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/home/jupyter-rouze/in')\n",
    "read = rio.open('reference_evapotranspiration/reference_evapotranspiration_2011011.tif')\n",
    "array = read.read(1)\n",
    "c = plt.imshow(array, origin='lower')\n",
    "plt.colorbar(c) \n",
    "plt.show()\n",
    "# from rasterio.transform import Affine\n",
    "\n",
    "# res = (array[-1] - array[0]) / 240.0\n",
    "# transform = Affine.translation(array[0] - res / 2, array[0] - res / 2) * Affine.scale(res, res)\n",
    "\n",
    "# from rasterio.plot import show\n",
    "# show(array, transform=read.transform)\n",
    "# import pyplot\n",
    "# pyplot.imshow(array, origin='lower')\n",
    "from rasterio import plot\n",
    "plot.show(read, origin='lower', transform=read.transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rio.plot.plotting_extent(read)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_list=grepfxn(\"uas\",year_block_files)\n",
    "var_name='eastward_wind'\n",
    "model_files\n",
    "tiffolder\n",
    "data_source\n",
    "to_clip=to_clip\n",
    "bounds=bounds\n",
    "pad_factor=pad_factor\n",
    "\n",
    "print(to_clip)\n",
    "fs = fsspec.filesystem('s3')\n",
    "fobj = fs.open(original_list[0])\n",
    "print(fobj)\n",
    "xds = xr.open_dataset(fobj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "final_list=[]\n",
    "j=0\n",
    "\n",
    "if((data_source == 'METDATA') or (data_source == 'gridMET') or (data_source == 'Historical1915-LIVNEH')):\n",
    "\n",
    "    fs = fsspec.filesystem('s3')\n",
    "    fobj = fs.open(original_list[j])\n",
    "    xds = xr.open_dataset(fobj)\n",
    "\n",
    "if((data_source == 'METDATA') or (data_source == 'gridMET')):\n",
    "    orig_crs = xds.coordinate_system\n",
    "else:\n",
    "    print('hello world')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "netcdf_var=xds[var_name]\n",
    "print(netcdf_var)\n",
    "if(data_source == 'LIVNEHhistorical1915'):\n",
    "    netcdf_var.rio.set_crs('EPSG:4326', inplace=True)\n",
    "\n",
    "final = netcdf_var.assign_coords(lon=(((netcdf_var.lon + 180) % 360) - 180))\n",
    "\n",
    "final.rio.set_spatial_dims(x_dim=\"lon\", y_dim=\"lat\")\n",
    "\n",
    "# netcdf_var.assign_coords(lon=(((netcdf_var.lon + 180) % 360) - 180))\n",
    "\n",
    "# netcdf_var.rio.set_spatial_dims(x_dim=\"lon\", y_dim=\"lat\")\n",
    "# final.data=np.flip(final.data,1) # turned off on 8/17/2020 for the gridMET data\n",
    "\n",
    "newfilename = original_list[j][:-3]+'.tif' # append .tif instead of .nc\n",
    "os.chdir('/home/jupyter-rouze')\n",
    "#             os.chdir('in/temp') # for local directory in mini-pangeo\n",
    "# os.chdir('in/temp')\n",
    "# os.getcwd()\n",
    "# bounds=gridMET_pr[0][0].bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "if (to_clip == 'True'):\n",
    "\n",
    "    lats = final.coords['lat'][:] \n",
    "    lons = final.coords['lon'][:]\n",
    "    # lat_bnds, lon_bnds = [38.6, 42.54], [-76.3, -74.23] # originall hard-coded\n",
    "    lat_bnds, lon_bnds = [bounds[0]-pad_factor, bounds[1]+pad_factor], [bounds[2]-pad_factor, bounds[3]+pad_factor]\n",
    "\n",
    "    lat_inds = np.where((lats > lat_bnds[0]) & (lats < lat_bnds[1]))[0]\n",
    "    lon_inds = np.where((lons > lon_bnds[0]) & (lons < lon_bnds[1]))[0]\n",
    "\n",
    "    subset_netcdf=final[:,lat_inds,lon_inds]\n",
    "    subset_netcdf.rio.set_spatial_dims(x_dim=\"lon\", y_dim=\"lat\")\n",
    "\n",
    "    local_file = 'in/temp/'+ original_list[0][-63:][:-3]+'.tif'\n",
    "\n",
    "    bucket = original_list[0][0:11]\n",
    "\n",
    "    bucket_filepath = original_list[0][12:]\n",
    "\n",
    "#                 os.getcwd()\n",
    "\n",
    "    subset_netcdf.rio.to_raster(local_file)\n",
    "    final_list.append(rio.open(local_file))\n",
    "\n",
    "\n",
    "else:\n",
    "\n",
    "    final.rio.to_raster(newfilename, driver='GTiff')\n",
    "\n",
    "print(final_list)\n",
    "    \n",
    "#         fs.close(fobj)\n",
    "\n",
    "#     s3_push_delete_local(local_file, bucket, bucket_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Loop by each time period block\n",
    "# First, create a data frame with start/end years\n",
    "\n",
    "# break down the name of each file into each metadata component\n",
    "# The section below is meant to convert netCDF files into geoTIFFs and combine them in a brick like equivalent object similar to R\n",
    "\n",
    "bounds=[southmost,northmost,westmost,eastmost]\n",
    "\n",
    "# local_file = 'in/temp/'+ grepfxn(\"pr\",year_block_files)[0][-61:][:-3]+'.tif'\n",
    "\n",
    "# bucket = grepfxn(\"pr\",year_block_files)[0][0:11]\n",
    "\n",
    "# bucket_filepath = grepfxn(\"pr\",year_block_files)[0][12:]\n",
    "\n",
    "# final_list.append(rio.open(fs.open(newfilename)))\n",
    "\n",
    "# fs.open(newfilename)\n",
    "\n",
    "# print(local_file)\n",
    "# print(bucket)\n",
    "# print(bucket_filepath)\n",
    "# print(grepfxn(\"pr\",year_block_files))\n",
    "\n",
    "# fobj.close()\n",
    "fs = fsspec.filesystem('s3')\n",
    "# grepfxn(\"rsds\",year_block_files)[0]\n",
    "\n",
    "# grepfxn(\"rsds\",year_block_files)[0]\n",
    "# fobj = fs.open(grepfxn(\"tasmax\",year_block_files)[0])\n",
    "# fobj2 = fs.open(grepfxn(\"tasmin\",year_block_files)[0])\n",
    "# fobj3 = fs.open(grepfxn(\"pr\",year_block_files)[0])\n",
    "\n",
    "# # print(type(fobj))\n",
    "# # print(type(fobj2))\n",
    "\n",
    "# print(fobj)\n",
    "# print(fobj2)\n",
    "# print(fobj3)\n",
    "\n",
    "# # print(fobj)\n",
    "# xds = xr.open_dataset(fobj)\n",
    "# xds2 = xr.open_dataset(fobj2)\n",
    "# xds3 = xr.open_dataset(fobj3)\n",
    "# print(fobj)\n",
    "\n",
    "# xds2 = xr.open_dataset(fobj2)\n",
    "\n",
    "# print(xds2)\n",
    "\n",
    "# type(fobj)\n",
    "# fobj.close()\n",
    "# fobj\n",
    "# type(fobj)\n",
    "\n",
    "# os.getcwd()\n",
    "\n",
    "# # fs = fsspec.filesystem('s3')\n",
    "# # fobj = fs.open(grepfxn(\"tasmin\",year_block_files)[0])\n",
    "# # print(fobj)\n",
    "# # xds = xr.open_dataset(fobj)\n",
    "\n",
    "# fs = fsspec.filesystem('s3')\n",
    "# fobj2 = fs.open(grepfxn(\"uas\",year_block_files)[0])\n",
    "# print(fobj2)\n",
    "# xds = xr.open_dataset(fobj2)\n",
    "\n",
    "# local_file = 'in/temp/'+ grepfxn(\"tasmin\",year_block_files)[0][-65:][:-3]+'.tif'\n",
    "# print(local_file)\n",
    "rcp_pr = lapply_brick(grepfxn(\"pr\",year_block_files), 'precipitation', model_files,tiffolder,data_source,to_clip=to_clip,bounds=bounds,pad_factor=pad_factor)\n",
    "# downwelling shortwave radiation\n",
    "# rcp_rsds = lapply_brick(grepfxn(\"rsds\",year_block_files), 'surface_downwelling_shortwave_flux_in_air', model_files,tiffolder,data_source,to_clip=to_clip,bounds=bounds,pad_factor=pad_factor)\n",
    "# maximum air temperature\n",
    "# rcp_tasmax = lapply_brick(grepfxn(\"tasmax\",year_block_files), 'air_temperature', model_files,tiffolder,data_source,to_clip=to_clip,bounds=bounds,pad_factor=pad_factor)\n",
    "# minimum air temperature\n",
    "# rcp_tasmin = lapply_brick(grepfxn(\"tasmin\",year_block_files), 'air_temperature', model_files,tiffolder,data_source,to_clip=to_clip,bounds=bounds,pad_factor=pad_factor)\n",
    "# Now repeat above for the rcp 8.5 model outputs below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "local_file = 'in/temp/'+ grepfxn(\"uas\",year_block_files)[-65:][0][:-3]+'.tif'\n",
    "print(local_file)\n",
    "# bucket = original_list[0][0:11]\n",
    "\n",
    "# bucket_filepath = original_list[0][12:]\n",
    "\n",
    "# #                 os.getcwd()\n",
    "\n",
    "# subset_netcdf.rio.to_raster(local_file)\n",
    "\n",
    "# s3_push_delete_local(local_file, bucket, bucket_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (data_source == \"METDATA\"):\n",
    "\n",
    "    # Whittle down the number of files if the folder contains both rcp 4.5 and rcp 8.5 files\n",
    "    # Right now, the code can only handle one model of METDATA output (8/21/2020)\n",
    "    rcp_all_files = [grepfxn(rcp_source,all_files)][0]\n",
    "\n",
    "    # Split models apart that are to be used for ensemble averaging\n",
    "    models_parsed = [x.strip() for x in model.split(',')]\n",
    "\n",
    "    # Iterate the files by each each specified model\n",
    "    models_list=[]\n",
    "    for i in range(len(models_parsed)):\n",
    "        model_files_loop = [grepfxn(models_parsed[i],rcp_all_files)][0]\n",
    "        models_list.append(model_files_loop)\n",
    "\n",
    "    # Flatten series of lists into one list\n",
    "    rcp_all_files = list(chain(*models_list))\n",
    "\n",
    "    # Find and compile the year blocks into a list\n",
    "    dfis=[]\n",
    "    for out in rcp_all_files:\n",
    "        a=out.split('_')\n",
    "        dfi = a[5]+'_'+a[6]\n",
    "        dfis.append(dfi)\n",
    "\n",
    "    # Distill the above list into unique year blocks, as there will be duplicates from \n",
    "    # multiple climate inputs\n",
    "    year_all=unique(dfis)\n",
    "\n",
    "    # For prototyping only\n",
    "    year_block=0\n",
    "    for year_block in range(0,len(year_all)):\n",
    "\n",
    "        year_block_files = grepfxn(year_all[year_block],rcp_all_files)\n",
    "        # Loop by each time period block\n",
    "        # First, create a data frame with start/end years\n",
    "\n",
    "        # break down the name of each file into each metadata component\n",
    "        # The section below is meant to convert netCDF files into geoTIFFs and combine them in a brick like equivalent object similar to R\n",
    "\n",
    "        bounds=[southmost,northmost,westmost,eastmost]\n",
    "\n",
    "        rcp_pr = lapply_brick(grepfxn(\"pr\",year_block_files), 'precipitation', model_files,tiffolder,data_source,to_clip=to_clip,bounds=bounds,pad_factor=pad_factor)\n",
    "        # downwelling shortwave radiation\n",
    "        rcp_rsds = lapply_brick(grepfxn(\"rsds\",year_block_files), 'surface_downwelling_shortwave_flux_in_air', model_files,tiffolder,data_source,to_clip=to_clip,bounds=bounds,pad_factor=pad_factor)\n",
    "        # maximum air temperature\n",
    "        rcp_tasmax = lapply_brick(grepfxn(\"tasmax\",year_block_files), 'air_temperature', model_files,tiffolder,data_source,to_clip=to_clip,bounds=bounds,pad_factor=pad_factor)\n",
    "        # minimum air temperature\n",
    "        rcp_tasmin = lapply_brick(grepfxn(\"tasmin\",year_block_files), 'air_temperature', model_files,tiffolder,data_source,to_clip=to_clip,bounds=bounds,pad_factor=pad_factor)\n",
    "        # Now repeat above for the rcp 8.5 model outputs below\n",
    "\n",
    "        if(data_source == 'METDATA'):\n",
    "\n",
    "            rcp_uas = lapply_brick(grepfxn(\"uas\",year_block_files), 'eastward_wind', model_files,tiffolder,data_source,to_clip=to_clip,bounds=bounds,pad_factor=pad_factor)\n",
    "\n",
    "            rcp_vas = lapply_brick(grepfxn(\"vas\",year_block_files), 'northward_wind', model_files,tiffolder,data_source,to_clip=to_clip,bounds=bounds,pad_factor=pad_factor)\n",
    "\n",
    "            rcp_rhsmax = lapply_brick(grepfxn(\"rhsmax\",year_block_files), 'relative_humidity', model_files,tiffolder,data_source,to_clip=to_clip,bounds=bounds,pad_factor=pad_factor)\n",
    "\n",
    "            rcp_rhsmin = lapply_brick(grepfxn(\"rhsmin\",year_block_files), 'relative_humidity', model_files,tiffolder,data_source,to_clip=to_clip,bounds=bounds,pad_factor=pad_factor)\n",
    "\n",
    "        # The section below is meant to convert netCDF files into geoTIFFs\n",
    "        # and combine them in a brick like equivalent object similar to R\n",
    "\n",
    "    ############################################# This ends the read nc file and stack all temporal bands\n",
    "\n",
    "        src = rio.open(elevfile)\n",
    "        # elevation_full_aggregate = aggregate_raster_inmem(src,scale=0.5)\n",
    "        aggoutput_name='elevation_aggregated.tif'\n",
    "        resample_raster_write(src, name= aggoutput_name,scale=0.5)\n",
    "        dst_filename='elevation_aggregated_resampled.tif'\n",
    "        match_filename=rcp_pr[0][0].name\n",
    "        reproject_raster(aggoutput_name, match_filename,dst_filename)\n",
    "\n",
    "        elevation_array=rio.open(dst_filename).read(1)\n",
    "\n",
    "        # from datetime import datetime - will need to update to make start/end adaptive (7/28/2020)\n",
    "        start_year=year_all[year_block][0:4]\n",
    "        end_year=year_all[year_block][5:9]\n",
    "\n",
    "        start=start_year+'-01-01'\n",
    "        end=end_year+'-12-31'\n",
    "        datetimes = pd.date_range(start=start,end=end)\n",
    "        i=10\n",
    "        for i in range(0,rcp_pr[0][0].count):\n",
    "\n",
    "            doy_loop = pd.Period(datetimes[i],freq='D').dayofyear\n",
    "            year_loop = pd.Period(datetimes[i],freq='D').year\n",
    "\n",
    "            # step 1: extract ith band from the raster stack\n",
    "            # step 2: stack those ith bands together\n",
    "            # step 3: do raster mean math from step 2\n",
    "            pr_stack=[]\n",
    "\n",
    "            # Purpose: create stacks of variables individually - this is like brick in R\n",
    "            pr_ensemble = []\n",
    "            rsds_ensemble = []\n",
    "            tasmax_ensemble = []\n",
    "            tasmin_ensemble = []\n",
    "\n",
    "            j = 0\n",
    "\n",
    "            # should be 1 array for each variable (mean of x ensembles for a given doy)\n",
    "            # rcp_pr[0][0].read(1, masked=False).shape\n",
    "            rcp_pr_doy = rastermath(rcp_pr[0], i)\n",
    "            rcp_rsds_doy = rastermath(rcp_rsds[0], i)\n",
    "            rcp_tasmax_doy = rastermath(rcp_tasmax[0], i)\n",
    "            rcp_tasmin_doy = rastermath(rcp_tasmin[0], i)\n",
    "\n",
    "            dims = np.shape(rcp_pr_doy[0])\n",
    "            rows = dims[0]\n",
    "            cols = dims[1]\n",
    "            constant_1_dat = np.full((rows,cols), 17.27)\n",
    "            constant_2_dat = np.full((rows,cols), 0.6108)\n",
    "            constant_3_dat = np.full((rows,cols), 273.15)\n",
    "            constant_4_dat = np.full((rows,cols), 237.3)\n",
    "\n",
    "            rcp_vs_tmax_array = constant_2_dat * np.exp(constant_1_dat * (rcp_tasmax_doy[0]-constant_3_dat) / ( (rcp_tasmax_doy[0]-constant_3_dat) + constant_4_dat)) # Equation S2.5\n",
    "            rcp_vs_tmin_array = constant_2_dat * np.exp(constant_1_dat * (rcp_tasmin_doy[0]-constant_3_dat) / ( (rcp_tasmin_doy[0]-constant_3_dat) + constant_4_dat)) # Equation S2.5\n",
    "            rcp_saturatedvapor_doy = (rcp_vs_tmax_array + rcp_vs_tmin_array)/2 \n",
    "\n",
    "            if(data_source == 'METDATA'): # line 180 from R script\n",
    "\n",
    "                # All of these are arrays by the way\n",
    "                rcp_rhsmax_doy = rastermath(rcp_rhsmax[0], i)\n",
    "                rcp_rhsmin_doy = rastermath(rcp_rhsmin[0], i)\n",
    "                rcp_uas_doy = rastermath(rcp_uas[0], i)\n",
    "                rcp_vas_doy = rastermath(rcp_vas[0], i)\n",
    "\n",
    "                # was below are just arrays, not metadata profiles\n",
    "                rcp_was_doy_10m = np.sqrt(rcp_uas_doy[0]**2 + rcp_vas_doy[0]**2 )\n",
    "\n",
    "                rcp_actualvapor_doy = (rcp_vs_tmin_array * rcp_rhsmax_doy[0]/100 + rcp_vs_tmax_array * rcp_rhsmin_doy[0]/100)/2\n",
    "\n",
    "            elif (data_source == \"Future_LIVNEH\"):\n",
    "\n",
    "                pressure = atmospheric_pressure(elevation_array)\n",
    "\n",
    "                rcp_huss_doy = rastermath(rcp_huss[0], i)\n",
    "\n",
    "                rcp_was_doy_10m = rastermath(rcp_was[0], i)\n",
    "\n",
    "                rcp_tasmean_doy = (rcp_tasmax_doy[0] + rcp_tasmin_doy[0])/2\n",
    "\n",
    "                rcp_rhmean_doy = relative_fromspecific(pressure,rcp_tasmean_doy, rcp_huss_doy[0])\n",
    "\n",
    "                rcp_actualvapor_doy = rcp_rhmean_doy / 100 * rcp_saturatedvapor_doy\n",
    "\n",
    "            # Compute the lon/lat coordinates with rasterio.warp.transform\n",
    "            da = xr.open_rasterio(rcp_pr[1])\n",
    "            da_r = rio.open(rcp_pr[1])\n",
    "            ny, nx = len(da['y']), len(da['x'])\n",
    "            longitude_array, latitude_array = np.meshgrid(da['x'], da['y'])\n",
    "\n",
    "            latitude_array_rad = latitude_array * (math.pi/180)\n",
    "\n",
    "            # Wind speed at 2 meters\n",
    "            z = np.full((rows,cols), 10)\n",
    "            array_487 = np.full((rows,cols), 4.87)\n",
    "            array_678 = np.full((rows,cols), 67.8)\n",
    "            array_542 = np.full((rows,cols), 5.42)\n",
    "\n",
    "            if (data_source == 'METDATA'):\n",
    "                rcp_was_doy_2m = rcp_was_doy_10m * array_487 / np.log(array_678*z - array_542) # Equation S5.20 for PET formulations other than Penman\n",
    "            else:\n",
    "                rcp_was_doy_2m = rcp_was_doy_10m[0] * array_487 / np.log(array_678*z - array_542) # Equation S5.20 for PET formulations other than Penman\n",
    "\n",
    "            doy_array = np.full((rows,cols), i+1)\n",
    "\n",
    "            rcp_pr_doy[1]['count']=1\n",
    "            rcp_tasmin_doy[1]['count']=1\n",
    "            rcp_tasmax_doy[1]['count']=1\n",
    "\n",
    "            # technically speaking, writing these arrays as geotiffs is optional (except precip), as technically only precip and ET0 are needed - however, they provide for good sanity checks.\n",
    "            write_geotiff(data=rcp_pr_doy[0],meta=rcp_pr_doy[1],var_name='precipitation',doy=doy_loop,year=year_loop,folder=output_folder)\n",
    "            write_geotiff(data=rcp_tasmin_doy[0],meta=rcp_tasmin_doy[1],var_name='airtemperature_min',doy=doy_loop,year=year_loop,folder=output_folder)\n",
    "            write_geotiff(data=rcp_tasmax_doy[0],meta=rcp_tasmax_doy[1],var_name='airtemperature_max',doy=doy_loop,year=year_loop,folder=output_folder)\n",
    "\n",
    "            # To-do: go ahead and developed ET0 directly as opposed to the R implementation(7/29)\n",
    "\n",
    "            ET0_inputarrays_rcp = [rcp_pr_doy[0], rcp_rsds_doy[0], rcp_tasmin_doy[0],\n",
    "                                         rcp_tasmax_doy[0],rcp_was_doy_2m,rcp_saturatedvapor_doy,\n",
    "                                         rcp_actualvapor_doy,elevation_array,latitude_array_rad,doy_array]\n",
    "\n",
    "            # NameError: name 'ET0_method' is not defined\n",
    "            if ET0_method  == \"yes\":\n",
    "              if ET0_crop != \"short\" and ET0_crop != \"tall\":\n",
    "                stop(\"Please enter 'short' or 'tall' for the desired reference crop type\")\n",
    "              else:\n",
    "                alpha = 0.23 # albedo for both short and tall crop\n",
    "                if (ET0_crop == \"short\"):\n",
    "                  z0 = 0.02 # roughness height for short grass\n",
    "                else:\n",
    "                  z0 = 0.1 # roughness height for tall grass\n",
    "            else:\n",
    "                z0 = 0.02 # roughness height for short grass\n",
    "                alpha = 0.25 # semi-desert short grass - will not be used for calculation - just informative\n",
    "\n",
    "            constants=[alpha, z0]\n",
    "\n",
    "            ET0_rcp = ET0_PM(ET0_inputarrays_rcp,ET0_method,ET0_winddat,ET0_crop,constants)\n",
    "            ET0_rcp.incoming_shortwave()\n",
    "            ET0_rcp.outgoing_shortwave()\n",
    "            ET0_rcp.outgoing_longwave()\n",
    "            ET0_rcp.net_radiation()\n",
    "            ET0_rcp_array_from_class = ET0_rcp.ET0_calcs()\n",
    "            ET0_rcp_array_final = ET0_rcp_array_from_class.astype('float32')\n",
    "\n",
    "            rcp_pr_doy[1]['count']=1\n",
    "            os.chdir(output_folder)\n",
    "            write_geotiff(data=ET0_rcp_array_final,meta=rcp_pr_doy[1],var_name='reference_evapotranspiration',\n",
    "                          doy=doy_loop,year=year_loop,folder=output_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
